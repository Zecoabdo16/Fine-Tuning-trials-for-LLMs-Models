{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Llama_Fine Tuning ( MCQ Task )"
      ],
      "metadata": {
        "id": "rOWkWCsATCO4"
      },
      "id": "rOWkWCsATCO4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation**"
      ],
      "metadata": {
        "id": "stdmiN20TTCN"
      },
      "id": "stdmiN20TTCN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbd586ec",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-08-14T13:16:28.981356Z",
          "iopub.status.busy": "2023-08-14T13:16:28.980642Z",
          "iopub.status.idle": "2023-08-14T13:19:48.262341Z",
          "shell.execute_reply": "2023-08-14T13:19:48.261010Z"
        },
        "papermill": {
          "duration": 199.291211,
          "end_time": "2023-08-14T13:19:48.265021",
          "exception": false,
          "start_time": "2023-08-14T13:16:28.973810",
          "status": "completed"
        },
        "tags": [],
        "id": "dbd586ec",
        "outputId": "55f80287-6054-46ab-ffde-ffa2dcbd070d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting accelerate==0.21.0\r\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (1.23.5)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (21.3)\r\n",
            "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (5.9.3)\r\n",
            "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (6.0)\r\n",
            "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0) (2.0.0)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.21.0) (3.0.9)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.12.2)\r\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (4.6.3)\r\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12)\r\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1)\r\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.2)\r\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.3)\r\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\r\n",
            "Installing collected packages: accelerate\r\n",
            "  Attempting uninstall: accelerate\r\n",
            "    Found existing installation: accelerate 0.20.3\r\n",
            "    Uninstalling accelerate-0.20.3:\r\n",
            "      Successfully uninstalled accelerate-0.20.3\r\n",
            "Successfully installed accelerate-0.21.0\r\n",
            "Requirement already satisfied: appdirs==1.4.4 in /opt/conda/lib/python3.10/site-packages (1.4.4)\r\n",
            "Collecting bitsandbytes==0.41.1\r\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\r\n",
            "Successfully installed bitsandbytes-0.41.1\r\n",
            "Collecting datasets==2.10.1\r\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (1.23.5)\r\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (11.0.0)\r\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (0.3.6)\r\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (1.5.3)\r\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (2.31.0)\r\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (4.65.0)\r\n",
            "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (3.2.0)\r\n",
            "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (0.70.14)\r\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (2023.6.0)\r\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (3.8.4)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (0.16.4)\r\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (21.3)\r\n",
            "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (0.18.0)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (6.0)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (23.1.0)\r\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (3.1.0)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (6.0.4)\r\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (4.0.2)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (1.9.2)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (1.3.3)\r\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (1.3.1)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (3.12.2)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (4.6.3)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.10.1) (3.0.9)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (3.4)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (1.26.15)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (2023.5.7)\r\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.10.1) (2.8.2)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.10.1) (2023.3)\r\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets==2.10.1) (1.16.0)\r\n",
            "Installing collected packages: datasets\r\n",
            "  Attempting uninstall: datasets\r\n",
            "    Found existing installation: datasets 2.1.0\r\n",
            "    Uninstalling datasets-2.1.0:\r\n",
            "      Successfully uninstalled datasets-2.1.0\r\n",
            "Successfully installed datasets-2.10.1\r\n",
            "Collecting fire==0.5.0\r\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
            "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0) (1.16.0)\r\n",
            "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0) (2.3.0)\r\n",
            "Building wheels for collected packages: fire\r\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
            "\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116949 sha256=07b454b02444551939d0de14d626ecc33b70d2ae6323effee44db0ca6b956302\r\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\r\n",
            "Successfully built fire\r\n",
            "Installing collected packages: fire\r\n",
            "Successfully installed fire-0.5.0\r\n",
            "Collecting git+https://github.com/huggingface/peft.git\r\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-id82u7ak\r\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-id82u7ak\r\n",
            "  Resolved https://github.com/huggingface/peft.git to commit a916465ad0970944f3241305071d9b79fae55b59\r\n",
            "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0.dev0) (1.23.5)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0.dev0) (21.3)\r\n",
            "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0.dev0) (5.9.3)\r\n",
            "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0.dev0) (6.0)\r\n",
            "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0.dev0) (2.0.0)\r\n",
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0.dev0) (4.30.2)\r\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0.dev0) (4.65.0)\r\n",
            "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0.dev0) (0.21.0)\r\n",
            "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0.dev0) (0.3.1)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.5.0.dev0) (3.0.9)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0.dev0) (3.12.2)\r\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0.dev0) (4.6.3)\r\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0.dev0) (1.12)\r\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0.dev0) (3.1)\r\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0.dev0) (3.1.2)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0.dev0) (0.16.4)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0.dev0) (2023.6.3)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0.dev0) (2.31.0)\r\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0.dev0) (0.13.3)\r\n",
            "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.5.0.dev0) (2023.6.0)\r\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0.dev0) (2.1.3)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0.dev0) (3.1.0)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0.dev0) (3.4)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0.dev0) (1.26.15)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0.dev0) (2023.5.7)\r\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.5.0.dev0) (1.3.0)\r\n",
            "Building wheels for collected packages: peft\r\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
            "\u001b[?25h  Created wheel for peft: filename=peft-0.5.0.dev0-py3-none-any.whl size=81186 sha256=e0e5813a0fba699071ded21df517a331f5a4266d5d1be5760d97d98f4117b3cb\r\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gii7by13/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\r\n",
            "Successfully built peft\r\n",
            "Installing collected packages: peft\r\n",
            "Successfully installed peft-0.5.0.dev0\r\n",
            "Collecting git+https://github.com/huggingface/transformers.git\r\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-95zzmqlx\r\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-95zzmqlx\r\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit e97deca9a3f4ddf2a6a44405ed928067d7b729f3\r\n",
            "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \b\\\b \bdone\r\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
            "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (3.12.2)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.16.4)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (1.23.5)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (21.3)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (6.0)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2023.6.3)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2.31.0)\r\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.13.3)\r\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.3.1)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (4.65.0)\r\n",
            "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0.dev0) (2023.6.0)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0.dev0) (4.6.3)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.32.0.dev0) (3.0.9)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (3.1.0)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (3.4)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (1.26.15)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (2023.5.7)\r\n",
            "Building wheels for collected packages: transformers\r\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
            "\u001b[?25h  Created wheel for transformers: filename=transformers-4.32.0.dev0-py3-none-any.whl size=7459102 sha256=e5b1e2e8e96f9afea600a30423556ea05682c4d7ec269cc66506ce4110bb9cac\r\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tqplqqw5/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\r\n",
            "Successfully built transformers\r\n",
            "Installing collected packages: transformers\r\n",
            "  Attempting uninstall: transformers\r\n",
            "    Found existing installation: transformers 4.30.2\r\n",
            "    Uninstalling transformers-4.30.2:\r\n",
            "      Successfully uninstalled transformers-4.30.2\r\n",
            "Successfully installed transformers-4.32.0.dev0\r\n",
            "Requirement already satisfied: torch==2.0.0 in /opt/conda/lib/python3.10/site-packages (2.0.0)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.12.2)\r\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (4.6.3)\r\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (1.12)\r\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.1)\r\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.1.2)\r\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.0) (2.1.3)\r\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.0) (1.3.0)\r\n",
            "Collecting sentencepiece==0.1.97\r\n",
            "  Downloading sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\r\n",
            "  Attempting uninstall: sentencepiece\r\n",
            "    Found existing installation: sentencepiece 0.1.99\r\n",
            "    Uninstalling sentencepiece-0.1.99:\r\n",
            "      Successfully uninstalled sentencepiece-0.1.99\r\n",
            "Successfully installed sentencepiece-0.1.97\r\n",
            "Requirement already satisfied: tensorboardX==2.6 in /opt/conda/lib/python3.10/site-packages (2.6)\r\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorboardX==2.6) (1.23.5)\r\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorboardX==2.6) (21.3)\r\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorboardX==2.6) (3.20.3)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorboardX==2.6) (3.0.9)\r\n",
            "Collecting gradio==3.23.0\r\n",
            "  Downloading gradio-3.23.0-py3-none-any.whl (15.8 MB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hRequirement already satisfied: aiofiles in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (22.1.0)\r\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (3.8.4)\r\n",
            "Requirement already satisfied: altair>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (5.0.1)\r\n",
            "Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (0.98.0)\r\n",
            "Collecting ffmpy (from gradio==3.23.0)\r\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\r\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (2023.6.0)\r\n",
            "Collecting httpx (from gradio==3.23.0)\r\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (0.16.4)\r\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (3.1.2)\r\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (2.2.0)\r\n",
            "Requirement already satisfied: markupsafe in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (2.1.3)\r\n",
            "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (3.7.1)\r\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.23.0)\r\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (1.23.5)\r\n",
            "Requirement already satisfied: orjson in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (3.9.1)\r\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (1.5.3)\r\n",
            "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (9.5.0)\r\n",
            "Requirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (1.10.10)\r\n",
            "Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (0.25.1)\r\n",
            "Collecting python-multipart (from gradio==3.23.0)\r\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (6.0)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (2.31.0)\r\n",
            "Collecting semantic-version (from gradio==3.23.0)\r\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\r\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (4.6.3)\r\n",
            "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (0.22.0)\r\n",
            "Requirement already satisfied: websockets>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (11.0.3)\r\n",
            "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio==3.23.0) (4.17.3)\r\n",
            "Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio==3.23.0) (0.12.0)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->gradio==3.23.0) (3.12.2)\r\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->gradio==3.23.0) (4.65.0)\r\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->gradio==3.23.0) (21.3)\r\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23.0) (0.1.0)\r\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23.0) (2.0.2)\r\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio==3.23.0) (2.8.2)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio==3.23.0) (2023.3)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (23.1.0)\r\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (3.1.0)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (6.0.4)\r\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (4.0.2)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (1.9.2)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (1.3.3)\r\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (1.3.1)\r\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio==3.23.0) (0.27.0)\r\n",
            "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.23.0) (2023.5.7)\r\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio==3.23.0)\r\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.23.0) (3.4)\r\n",
            "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.23.0) (1.3.0)\r\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0) (1.1.0)\r\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0) (0.11.0)\r\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0) (4.40.0)\r\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0) (1.4.4)\r\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0) (3.0.9)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->gradio==3.23.0) (1.26.15)\r\n",
            "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn->gradio==3.23.0) (8.1.3)\r\n",
            "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->gradio==3.23.0) (0.14.0)\r\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio==3.23.0) (3.7.0)\r\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23.0) (0.19.3)\r\n",
            "Requirement already satisfied: uc-micro-py in /opt/conda/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.23.0) (1.0.2)\r\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->gradio==3.23.0) (1.16.0)\r\n",
            "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio==3.23.0) (1.1.1)\r\n",
            "Building wheels for collected packages: ffmpy\r\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
            "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5596 sha256=0836d696e70c3601768e4d401d784bfa13edf121653323ffcebb8d4633238ce0\r\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\r\n",
            "Successfully built ffmpy\r\n",
            "Installing collected packages: ffmpy, semantic-version, python-multipart, mdit-py-plugins, httpcore, httpx, gradio\r\n",
            "  Attempting uninstall: mdit-py-plugins\r\n",
            "    Found existing installation: mdit-py-plugins 0.4.0\r\n",
            "    Uninstalling mdit-py-plugins-0.4.0:\r\n",
            "      Successfully uninstalled mdit-py-plugins-0.4.0\r\n",
            "Successfully installed ffmpy-0.3.1 gradio-3.23.0 httpcore-0.17.3 httpx-0.24.1 mdit-py-plugins-0.3.3 python-multipart-0.0.6 semantic-version-2.10.0\r\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate==0.21.0\n",
        "!pip install appdirs==1.4.4\n",
        "!pip install bitsandbytes==0.41.1\n",
        "!pip install datasets==2.10.1\n",
        "!pip install fire==0.5.0\n",
        "!pip install git+https://github.com/huggingface/peft.git\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install torch==2.0.0\n",
        "!pip install sentencepiece==0.1.97\n",
        "!pip install tensorboardX==2.6\n",
        "!pip install gradio==3.23.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Used Libraries**"
      ],
      "metadata": {
        "id": "-FvRfrNFTc8Q"
      },
      "id": "-FvRfrNFTc8Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b294e724",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-14T13:19:48.305710Z",
          "iopub.status.busy": "2023-08-14T13:19:48.305348Z",
          "iopub.status.idle": "2023-08-14T13:20:15.050934Z",
          "shell.execute_reply": "2023-08-14T13:20:15.050048Z"
        },
        "papermill": {
          "duration": 26.767922,
          "end_time": "2023-08-14T13:20:15.053602",
          "exception": false,
          "start_time": "2023-08-14T13:19:48.285680",
          "status": "completed"
        },
        "tags": [],
        "id": "b294e724",
        "outputId": "8de71e02-42dc-42e2-84db-692c8d39a61d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import transformers\n",
        "import textwrap\n",
        "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
        "import os\n",
        "import sys\n",
        "from typing import List\n",
        "\n",
        "import fire\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        "    prepare_model_for_int8_training,\n",
        ")\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(rc={'figure.figsize':(10, 7)})\n",
        "sns.set(rc={'figure.dpi':100})\n",
        "sns.set(style='white', palette='muted', font_scale=1.2)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DEVICE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLAMA Base Model_7B AND IT's Tokenizer**"
      ],
      "metadata": {
        "id": "AvdgHV4DUDra"
      },
      "id": "AvdgHV4DUDra"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "607757e7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-14T13:20:15.185651Z",
          "iopub.status.busy": "2023-08-14T13:20:15.185302Z",
          "iopub.status.idle": "2023-08-14T13:23:04.324950Z",
          "shell.execute_reply": "2023-08-14T13:23:04.324050Z"
        },
        "papermill": {
          "duration": 169.161312,
          "end_time": "2023-08-14T13:23:04.327236",
          "exception": false,
          "start_time": "2023-08-14T13:20:15.165924",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "08718aa629904a0bb6ba158901275329",
            "96f32c5de1fc45cebf1d1400de27b799",
            "8cf35b6667ed445e974fbf2f62ead714",
            "6ebcce9e3fad466b8232304288a6b1a1",
            "58f0bff58fff4a65b40f7fffb54a9c12",
            "eff6e650a2d244b9bc920e28828de380",
            "3811c7d9161f4c49b928079d45b33b25",
            "0ab660db15444153aeaec484461e79fb",
            "5d787867feaf471293046cdaafa038df",
            "581e7b473cb14310a5a2baad6af8e882",
            "accd5d14e72a4d0e8311174c739201ac",
            "ab71527b0f71439bb6a19065fe5e48ac",
            "776120581e364fbf86ba656b0035174a",
            "2004eab39b0a4d448a4afe4fb51e4fa3",
            "8d05c2f1be2843ffa1a1eb3894dcede2",
            "e1e839430ff0485ca717a7cf3501de34",
            "8c483ed12950465daae8118c4f6426cf",
            "3d14770594c64457a879d59b4cfb8fff",
            "be18bc594dc7473a9872574361cd0c54",
            "2bb3203647ed4967b4386eca98df3622",
            "2e0590d91bcf4686a7469c9aa2d200ae",
            "89303aaa3f45470daa5cc1a0c8a5292a",
            "9890d612532c48bdbc092b2f508184c8",
            "2337c46ba4204e3fad6c10e21f944a66",
            "c23f034276d04360b49e40eab03fac81",
            "78b86cab63f84176a69de47e768c38b9",
            "72c4745449a84130b6c04be50e996529",
            "8d70df6b4ddb403ca5a62cb231c144a0",
            "d3ad11fc6f3c4552b7938a98e55d8fe2",
            "85d1a31e683a49c0b510ef46097df205",
            "b44c9445b11444d59a1e817e7fbfb11f",
            "6b27a18f36c84205b59be1040123afd9",
            "92208399e7064eef9616eeae36c98e0d",
            "0b0af14fd7274180a16eacf624169895",
            "7874ef013766472bb7567786435cd858",
            "b56d01ed1d6d405bbd013c696fa07cff",
            "88fb43d3c45146e7ad52b0063bf30801",
            "b2909d751e3b48b0b1e1cf11cfe7a187",
            "4e0aeec26ee54de8a6e4cc46ed0b2643",
            "0c5d0ee2f0fb47e4a88bfb3f7977c599",
            "7c135936acb149cc9a60b60d042d0d98"
          ]
        },
        "id": "607757e7",
        "outputId": "d4c7e360-c04e-4bd6-fb5f-a28bee17c380"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08718aa629904a0bb6ba158901275329",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/427 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96f32c5de1fc45cebf1d1400de27b799",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)model.bin.index.json:   0%|          | 0.00/25.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cf35b6667ed445e974fbf2f62ead714",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ebcce9e3fad466b8232304288a6b1a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00001-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58f0bff58fff4a65b40f7fffb54a9c12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00002-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eff6e650a2d244b9bc920e28828de380",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00003-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3811c7d9161f4c49b928079d45b33b25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00004-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ab660db15444153aeaec484461e79fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00005-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d787867feaf471293046cdaafa038df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00006-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "581e7b473cb14310a5a2baad6af8e882",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00007-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "accd5d14e72a4d0e8311174c739201ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00008-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab71527b0f71439bb6a19065fe5e48ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00009-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "776120581e364fbf86ba656b0035174a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00010-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2004eab39b0a4d448a4afe4fb51e4fa3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00011-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d05c2f1be2843ffa1a1eb3894dcede2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00012-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1e839430ff0485ca717a7cf3501de34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00013-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c483ed12950465daae8118c4f6426cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00014-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d14770594c64457a879d59b4cfb8fff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00015-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be18bc594dc7473a9872574361cd0c54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00016-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bb3203647ed4967b4386eca98df3622",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00017-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e0590d91bcf4686a7469c9aa2d200ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00018-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89303aaa3f45470daa5cc1a0c8a5292a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00019-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9890d612532c48bdbc092b2f508184c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00020-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2337c46ba4204e3fad6c10e21f944a66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00021-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c23f034276d04360b49e40eab03fac81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00022-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78b86cab63f84176a69de47e768c38b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00023-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72c4745449a84130b6c04be50e996529",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00024-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d70df6b4ddb403ca5a62cb231c144a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00025-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3ad11fc6f3c4552b7938a98e55d8fe2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00026-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85d1a31e683a49c0b510ef46097df205",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00027-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b44c9445b11444d59a1e817e7fbfb11f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00028-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b27a18f36c84205b59be1040123afd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00029-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92208399e7064eef9616eeae36c98e0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00030-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b0af14fd7274180a16eacf624169895",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00031-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7874ef013766472bb7567786435cd858",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00032-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b56d01ed1d6d405bbd013c696fa07cff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)l-00033-of-00033.bin:   0%|          | 0.00/524M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88fb43d3c45146e7ad52b0063bf30801",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2909d751e3b48b0b1e1cf11cfe7a187",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e0aeec26ee54de8a6e4cc46ed0b2643",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c5d0ee2f0fb47e4a88bfb3f7977c599",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c135936acb149cc9a60b60d042d0d98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
            "The class this function is called from is 'LlamaTokenizer'.\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565, and set the legacy attribute accordingly.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "BASE_MODEL = \"decapoda-research/llama-7b-hf\"\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    load_in_8bit=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "tokenizer = LlamaTokenizer.from_pretrained(BASE_MODEL)\n",
        "\n",
        "tokenizer.pad_token_id = (\n",
        "    0  # unk. we want this to be different from the eos token\n",
        ")\n",
        "tokenizer.padding_side = \"left\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loading data in json (optional)**"
      ],
      "metadata": {
        "id": "1aVB8yKLUOhZ"
      },
      "id": "1aVB8yKLUOhZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fc818e7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-14T13:23:04.383424Z",
          "iopub.status.busy": "2023-08-14T13:23:04.381866Z",
          "iopub.status.idle": "2023-08-14T13:23:05.386860Z",
          "shell.execute_reply": "2023-08-14T13:23:05.385780Z"
        },
        "papermill": {
          "duration": 1.034527,
          "end_time": "2023-08-14T13:23:05.388948",
          "exception": false,
          "start_time": "2023-08-14T13:23:04.354421",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "e91ad0fc86924209bd0005028dbaf86a",
            "5bf5f1f72fc344728e74dc5e48c87fa0",
            "4914f903dc90467580cc8524f460f302",
            "3f5e7765b0964e6aa662b8a97ad7f5fb"
          ]
        },
        "id": "2fc818e7",
        "outputId": "ffe273cb-b187-453d-e64b-a4ce9fde66d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-96ef49803cf61098/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e91ad0fc86924209bd0005028dbaf86a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bf5f1f72fc344728e74dc5e48c87fa0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4914f903dc90467580cc8524f460f302",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-96ef49803cf61098/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f5e7765b0964e6aa662b8a97ad7f5fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'question', 'A', 'B', 'C', 'D', 'E', 'answer'],\n",
              "    num_rows: 20493\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = load_dataset(\"json\", data_files=\"/kaggle/input/json-rania/alpaca_MCQ.json\")\n",
        "data[\"train\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7d4b2b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-14T13:23:05.447426Z",
          "iopub.status.busy": "2023-08-14T13:23:05.447053Z",
          "iopub.status.idle": "2023-08-14T13:23:05.452616Z",
          "shell.execute_reply": "2023-08-14T13:23:05.451633Z"
        },
        "papermill": {
          "duration": 0.038256,
          "end_time": "2023-08-14T13:23:05.454914",
          "exception": false,
          "start_time": "2023-08-14T13:23:05.416658",
          "status": "completed"
        },
        "tags": [],
        "id": "cc7d4b2b"
      },
      "outputs": [],
      "source": [
        "CUTOFF_LEN=256\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**prompt shape and preprocessing**"
      ],
      "metadata": {
        "id": "TDFviWrzUuNC"
      },
      "id": "TDFviWrzUuNC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0890d59",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-14T13:23:05.514380Z",
          "iopub.status.busy": "2023-08-14T13:23:05.514086Z",
          "iopub.status.idle": "2023-08-14T13:23:05.524217Z",
          "shell.execute_reply": "2023-08-14T13:23:05.523318Z"
        },
        "papermill": {
          "duration": 0.042477,
          "end_time": "2023-08-14T13:23:05.526279",
          "exception": false,
          "start_time": "2023-08-14T13:23:05.483802",
          "status": "completed"
        },
        "tags": [],
        "id": "c0890d59"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_prompt(data_point):\n",
        "    return f\"\"\"Below is an instruction that describes a task, with The Question and Choices which are called A,B,C,D,E and the answer\n",
        "     that provides further context. Write a response that appropriately completes the request.  # noqa: E501\n",
        "### Instruction:\n",
        "{data_point[\"instruction\"]}\n",
        "\n",
        "### question\n",
        "{data_point[\"question\"]}\n",
        "\n",
        "### A:\n",
        "{data_point[\"A\"]}\n",
        "\n",
        "### B:\n",
        "{data_point[\"B\"]}\n",
        "\n",
        "### C:\n",
        "{data_point[\"C\"]}\n",
        "\n",
        "### D:\n",
        "{data_point[\"D\"]}\n",
        "\n",
        "### E:\n",
        "{data_point[\"E\"]}\n",
        "\n",
        "### Response:\n",
        "{data_point[\"answer\"]}\"\"\"\n",
        "\n",
        "\n",
        "def tokenize(prompt, add_eos_token=True):\n",
        "    result = tokenizer(\n",
        "        prompt,\n",
        "        truncation=True,\n",
        "        max_length=CUTOFF_LEN,\n",
        "        padding=False,\n",
        "        return_tensors=None,\n",
        "    )\n",
        "    if (\n",
        "        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
        "        and len(result[\"input_ids\"]) < CUTOFF_LEN\n",
        "        and add_eos_token\n",
        "    ):\n",
        "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
        "        result[\"attention_mask\"].append(1)\n",
        "\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "\n",
        "    return result\n",
        "\n",
        "def generate_and_tokenize_prompt(data_point):\n",
        "    full_prompt = generate_prompt(data_point)\n",
        "    tokenized_full_prompt = tokenize(full_prompt)\n",
        "    return tokenized_full_prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**split the data and apply the preprocessing**"
      ],
      "metadata": {
        "id": "yqHMaaA6U2iE"
      },
      "id": "yqHMaaA6U2iE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf24a7d0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-14T13:23:05.583190Z",
          "iopub.status.busy": "2023-08-14T13:23:05.582395Z",
          "iopub.status.idle": "2023-08-14T13:23:50.996015Z",
          "shell.execute_reply": "2023-08-14T13:23:50.995037Z"
        },
        "papermill": {
          "duration": 45.443444,
          "end_time": "2023-08-14T13:23:50.998154",
          "exception": false,
          "start_time": "2023-08-14T13:23:05.554710",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "af115771f16949f68e5eb5a6eccc4096",
            "248e040723c04ef1b0a582b735d04f1b"
          ]
        },
        "id": "cf24a7d0",
        "outputId": "54090ee3-c564-4840-8bac-b4f13125715a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af115771f16949f68e5eb5a6eccc4096",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20293 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "248e040723c04ef1b0a582b735d04f1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "train_val = data[\"train\"].train_test_split(\n",
        "    test_size=200, shuffle=True, seed=42\n",
        ")\n",
        "train_data = (\n",
        "    train_val[\"train\"].map(generate_and_tokenize_prompt)\n",
        ")\n",
        "val_data = (\n",
        "    train_val[\"test\"].map(generate_and_tokenize_prompt)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e83ae3b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-14T13:23:51.057599Z",
          "iopub.status.busy": "2023-08-14T13:23:51.057275Z",
          "iopub.status.idle": "2023-08-14T13:23:51.064004Z",
          "shell.execute_reply": "2023-08-14T13:23:51.063023Z"
        },
        "papermill": {
          "duration": 0.037591,
          "end_time": "2023-08-14T13:23:51.066020",
          "exception": false,
          "start_time": "2023-08-14T13:23:51.028429",
          "status": "completed"
        },
        "tags": [],
        "id": "0e83ae3b",
        "outputId": "56ae8234-2f55-4e23-f3b8-d779bd17e736"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'question', 'A', 'B', 'C', 'D', 'E', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 20293\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lora configuration**"
      ],
      "metadata": {
        "id": "O1PhPP_XU75m"
      },
      "id": "O1PhPP_XU75m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a78625",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-14T13:23:51.121400Z",
          "iopub.status.busy": "2023-08-14T13:23:51.121111Z",
          "iopub.status.idle": "2023-08-14T13:23:51.126330Z",
          "shell.execute_reply": "2023-08-14T13:23:51.125335Z"
        },
        "papermill": {
          "duration": 0.035342,
          "end_time": "2023-08-14T13:23:51.128384",
          "exception": false,
          "start_time": "2023-08-14T13:23:51.093042",
          "status": "completed"
        },
        "tags": [],
        "id": "10a78625"
      },
      "outputs": [],
      "source": [
        "\n",
        "LORA_R = 12\n",
        "LORA_ALPHA = 16\n",
        "LORA_DROPOUT= 0.05\n",
        "LORA_TARGET_MODULES = [\n",
        "    \"q_proj\",\n",
        "    \"v_proj\",\n",
        "]\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "MICRO_BATCH_SIZE = 4\n",
        "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
        "LEARNING_RATE = 3e-4\n",
        "TRAIN_STEPS = 300\n",
        "OUTPUT_DIR = \"./\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**prepare model for 8bit training then apply Lora configeration**"
      ],
      "metadata": {
        "id": "aeRkmTgtU_Nv"
      },
      "id": "aeRkmTgtU_Nv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ff836c0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-14T13:23:51.185418Z",
          "iopub.status.busy": "2023-08-14T13:23:51.184590Z",
          "iopub.status.idle": "2023-08-14T13:24:01.406232Z",
          "shell.execute_reply": "2023-08-14T13:24:01.404648Z"
        },
        "papermill": {
          "duration": 10.253084,
          "end_time": "2023-08-14T13:24:01.408422",
          "exception": false,
          "start_time": "2023-08-14T13:23:51.155338",
          "status": "completed"
        },
        "tags": [],
        "id": "5ff836c0",
        "outputId": "ba7058aa-1e1e-4004-b794-08ddab90cc3e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 6,291,456 || all params: 6,744,707,072 || trainable%: 0.09327989982127426\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = prepare_model_for_int8_training(model)\n",
        "config = LoraConfig(\n",
        "    r=LORA_R,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    target_modules=LORA_TARGET_MODULES,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "model = get_peft_model(model, config)\n",
        "model.print_trainable_parameters()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**training parameters**"
      ],
      "metadata": {
        "id": "Np1UeLzKVQMp"
      },
      "id": "Np1UeLzKVQMp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73e60635",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-14T13:24:01.466964Z",
          "iopub.status.busy": "2023-08-14T13:24:01.466045Z",
          "iopub.status.idle": "2023-08-14T13:24:01.492405Z",
          "shell.execute_reply": "2023-08-14T13:24:01.491479Z"
        },
        "papermill": {
          "duration": 0.057501,
          "end_time": "2023-08-14T13:24:01.494558",
          "exception": false,
          "start_time": "2023-08-14T13:24:01.437057",
          "status": "completed"
        },
        "tags": [],
        "id": "73e60635"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_arguments = transformers.TrainingArguments(\n",
        "    per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "    warmup_steps=100,\n",
        "    max_steps=TRAIN_STEPS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    optim=\"adamw_torch\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    eval_steps=75,\n",
        "    save_steps=75,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"tensorboard\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**apply data_collator**"
      ],
      "metadata": {
        "id": "XNjJm4M7VVwp"
      },
      "id": "XNjJm4M7VVwp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "734805dd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-14T13:24:01.553359Z",
          "iopub.status.busy": "2023-08-14T13:24:01.552512Z",
          "iopub.status.idle": "2023-08-14T13:24:02.110327Z",
          "shell.execute_reply": "2023-08-14T13:24:02.109050Z"
        },
        "papermill": {
          "duration": 0.590153,
          "end_time": "2023-08-14T13:24:02.113317",
          "exception": false,
          "start_time": "2023-08-14T13:24:01.523164",
          "status": "completed"
        },
        "tags": [],
        "id": "734805dd"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_collator = transformers.DataCollatorForSeq2Seq(\n",
        "    tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and Results**"
      ],
      "metadata": {
        "id": "7NE5-8q-VgE-"
      },
      "id": "7NE5-8q-VgE-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa9ac52b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-14T13:24:02.171807Z",
          "iopub.status.busy": "2023-08-14T13:24:02.170839Z",
          "iopub.status.idle": "2023-08-14T21:31:14.886120Z",
          "shell.execute_reply": "2023-08-14T21:31:14.885087Z"
        },
        "papermill": {
          "duration": 29232.746636,
          "end_time": "2023-08-14T21:31:14.888389",
          "exception": false,
          "start_time": "2023-08-14T13:24:02.141753",
          "status": "completed"
        },
        "tags": [],
        "id": "aa9ac52b",
        "outputId": "213e693a-82dd-4f1a-8ee4-a53b393c946d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 8:05:35, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.909700</td>\n",
              "      <td>0.905228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.904500</td>\n",
              "      <td>0.833389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.864900</td>\n",
              "      <td>0.813375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.843000</td>\n",
              "      <td>0.806926</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    args=training_arguments,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "model.config.use_cache = False\n",
        "old_state_dict = model.state_dict\n",
        "model.state_dict = (\n",
        "    lambda self, *_, **__: get_peft_model_state_dict(\n",
        "        self, old_state_dict()\n",
        "    )\n",
        ").__get__(model, type(model))\n",
        "\n",
        "model = torch.compile(model)\n",
        "\n",
        "trainer.train()\n",
        "model.save_pretrained(OUTPUT_DIR)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 29703.069063,
      "end_time": "2023-08-14T21:31:18.395736",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-08-14T13:16:15.326673",
      "version": "2.4.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}